<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
    <meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="stylesheet" href="asserts/jemdoc.css" type="text/css" />

    <!--    <link rel="shortcut icon" href="./Files/favicon.ico">-->
    <title>Zeming Li</title>
    <style>
        /*body {*/
        /*    font-family: "Lato", sans-serif;*/
        /*}*/

        .navbar {
            overflow: hidden;
            background-color: #333;
            position: fixed;
            top: 0;
            width: 100%;
            opacity: 0.7;
        }

        .navbar ul {
            text-align: center;
            padding: 0;
            margin: 0;
        }

        .navbar li {
            display: inline-block;
        }
        .navbar a {
            display: block;
            color: #f2f2f2;
            text-align: center;
            padding: 12px 13px;
            text-decoration: none;
            font-size: 15px;
            transition: 0.4s;
        }

        .navbar a:hover {
            background: #f1f1f1;
            color: black;
        }

        /*.navbar a.active {*/
        /*    background-color: #4CAF50;*/
        /*    color: white;*/
        /*}*/

        a {
            color: #00008b;
            vertical-align: baseline;
        }

        blockquote {
            /*border-left: .5em solid #40AA53;*/
            border-left: 0.5em solid #93ba9a;
            /*border-left: 1em solid #d3d3d3;*/
            padding: 0 1em;
            margin-left: 0;
        }
    </style>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-41537783-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() {
            dataLayer.push(arguments);
        }
        gtag("js", new Date());

        gtag("config", "UA-41537783-1");
    </script>
</head>

<body>
<div class="navbar">
    <ul>
        <li><a href="#Home">Home</a></li>
        <li><a href="#News">News</a></li>
        <li><a href="#Publications">Publications</a></li>
        <li><a href="#Awards">Awards</a></li>
    </ul>
</div>

<a id="home" class="anchor"></a>

<div id="container">
    <div class="container">
        <table class="imgtable">
            <tr>
                <td align="left">
                    <a href="./">
                        <font size="5">Zeming Li (</font>
                        <font size="5" font-style="font-family:monospace,Microsoft YaHei">黎泽明</font>
                        <font size="5">)</font>
                    </a>

                    <br />
                    <br />

                    Director of Base-Detection Team in
                    <a href="https://megvii.com/technologies/megvii_research?num=1">Megvii Research</a>. Previously, I got my M.E. from THU in 2018. <br />
                    <br />
                    My research interests focus on the computer vision and artificial intelligence, specifically on the topic of object detection(2D/3D), unsupervised/semi-supervised
                    learning, and efficient neural-network design.

                    <br />
                    <br />
                    <b>Contact:</b><a href="mailto:lizeming@megvii.com">lizeming@megvii.com (prior) </a>,
                    <a href="mailto:zengarden2009@gmail.com">zengarden2009@gmail.com</a>

                    <br />
                    <br />
                    <a href="https://scholar.google.com/citations?user=XdTqWS0AAAAJ&hl=en" target="_blank">Google Scholar</a> | <a href="https://github.com/zengarden" target="_blank">GitHub</a> |
                    <a href="https://orcid.org/0000-0002-1599-2853" target="_blank">ORCID</a>
                </td>

                <td>
                    <a href="./"><img src="./asserts/me_circle.jpg" alt="" height="215px" /></a>&nbsp;
                </td>
            </tr>
        </table>

        <a name="News"><h2>News</h2></a>
        <ul>
            <li><font color="#FF0000">[2020.10]</font> Two papers are accepted by NeurIPS2020.</li>
            <li><font color="#FF0000">[2020.07]</font> One paper is accepted by ECCV2020 as an <b>Oral Presentation. </b></li>
            <li><font color="#FF0000">[2020.03]</font> One paper is accepted by CVPR2020 as an <b>Oral Presentation. </b></li>
            <li>
                <font color="#FF0000">[2019.10]</font> <a href="http://cocodataset.org/workshop/coco-mapillary-iccv-2019.html" target="_blank">COCO and Mapillary Challenges 2019 Competition</a> Winner Award, and Best Paper Award,
                ICCV 2019
            </li>
            <li>
                <font color="#FF0000">[2019.6]</font>
                Our largest object detection dataset Objects365 with fine annotations are released in
                <a href="http://www.objects365.org/workshop2019.html" target="_blank"> Detection In the Wild (DIW2019) Challenge</a>, CVPR 2019.
            </li>
        </ul>

        <!--        Publications             -->
        <a name="Publications"><h2>Publications</h2></a>
        <p><sup>+</sup> Equal contribution</p>

        <blockquote>
            <p>
                <a target="_blank" href="https://papers.nips.cc/paper/2020/file/7f6caf1f0ba788cd7953d817724c2b6e-Paper.pdf"> Fine-Grained Dynamic Head for Object Detection</a>
                <br />
                Lin Song, Yanwei Li, Zhengkai Jiang, <b>Zeming Li</b>, Hongbin Sun, Jian Sun, Nanning Zheng
                <br />
                <i>NeurIPS, 2020,</i>
                <font color="#808080">
                    <b>
                        <a href="https://github.com/StevenGrove/DynamicHead">
                            <font color="#FF0000">code/models</font>
                        </a>
                    </b>
                </font>
            </p>
        </blockquote>

        <blockquote>
            <p>
                <a target="_blank" href="https://papers.nips.cc/paper/2020/file/2952351097998ac1240cb2ab7333a3d2-Paper.pdf"> Rethinking Learnable Tree Filter for Generic Feature Transform</a>
                <br />
                Lin Song, Yanwei Li, Zhengkai Jiang, <b>Zeming Li</b>, Xiangyu Zhang, Hongbin Sun, Jian Sun, Nanning Zheng
                <br />
                <i>NeurIPS, 2020,</i>
                <font color="#808080">
                    <b>
                        <a href="https://github.com/StevenGrove/LearnableTreeFilterV2">
                            <font color="#FF0000">code/models</font>
                        </a>
                    </b>
                </font>
            </p>
        </blockquote>

        <blockquote>
            <p>
                <a target="_blank" href="https://arxiv.org/pdf/2007.11056v1.pdf"> BorderDet: Border Feature for Dense Object Detection</a>
                <br />
                Han Qiu, Yuchen Ma, <b>Zeming Li</b>, Songtao Liu, Jian Sun
                <br />
                <i>ECCV <b>Oral</b>, 2020,</i>
                <font color="#808080">
                    <b>
                        <a href="https://github.com/Megvii-BaseDetection/BorderDet">
                            <font color="#FF0000">code/models</font>
                        </a>
                    </b>
                </font>
            </p>
        </blockquote>

        <blockquote>
            <p>
                <a target="_blank" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Learning_Dynamic_Routing_for_Semantic_Segmentation_CVPR_2020_paper.pdf"> Learning Dynamic Routing for Semantic Segmentation</a>
                <br />
                Yanwei Li, Lin Song, Yukang Chen, <b>Zeming Li</b>, Xiangyu Zhang, Xingang Wang, Jian Sun
                <br />
                <i>CVPR <b>Oral</b>, 2020,</i>
                <font color="#808080">
                    <b>
                        <a href="https://github.com/yanwei-li/DynamicRouting">
                            <font color="#FF0000">code/models</font>
                        </a>
                    </b>
                </font>
            </p>
        </blockquote>

        <blockquote>
            <p>
                <a target="_blank" href="https://papers.nips.cc/paper/8448-learnable-tree-filter-for-structure-preserving-feature-transform.pdf"> Learnable Tree Filter for Structure-preserving Feature Transform</a>
                <br />
                Lin Song<sup>+</sup>,Yanwei Li<sup>+</sup>, <b>Zeming Li</b>, Gang Yu, Hongbin Sun, Jian Sun
                <br />
                <i>NeurIPS, 2019,</i>
                <font color="#808080">
                    <b>
                        <a href="https://github.com/StevenGrove/TreeFilter-Torch">
                            <font color="#FF0000">code/models</font>
                        </a>
                    </b>
                </font>
            </p>
        </blockquote>

        <blockquote>
            <p>
                <a target="_blank" href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Qin_ThunderNet_Towards_Real-Time_Generic_Object_Detection_on_Mobile_Devices_ICCV_2019_paper.pdf">
                    ThunderNet: Towards Real-time Generic Object Detection
                </a>
                <br />
                Zheng Qin<sup>+</sup>, <b>Zeming Li<sup>+</sup></b>, Yiping Bao, Gang Yu, Yuxing Peng, Jian Sun
                <br />
                <i>ICCV, 2019</i>
            </p>
        </blockquote>

        <blockquote>
            <p>
                <a target="_blank" href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Shao_Objects365_A_Large-Scale_High-Quality_Dataset_for_Object_Detection_ICCV_2019_paper.pdf">
                    Objects365: A Large-scale, High-quality Dataset for Object Detection
                </a>
                <br />
                Shuai Shao<sup>+</sup>, <b>Zeming Li<sup>+</sup></b>, Tianyuan Zhang<sup>+</sup>, Chao Peng<sup>+</sup>, Gang Yu, Xiangyu Zhang, Jing Li, Jian Sun
                <br />
                <i>ICCV, 2019</i>,
                <font color="#808080">
                    <b>
                        <a href="https://www.objects365.org/overview.html">
                            <font color="#FF0000">dataset</font>
                        </a>
                    </b>
                </font>
            </p>
        </blockquote>

        <blockquote>
            <p>
                <a target="_blank" href="https://papers.nips.cc/paper/7315-metaanchor-learning-to-detect-objects-with-customized-anchors.pdf"> MetaAnchor: Learning to Detect Objects with Customized Anchors</a>
                <br />
                Tong Yang, Xiangyu Zhang, <b>Zeming Li</b>, Wenqiang Zhang, Jian Sun
                <br />
                <i>NeurIPS, 2018</i>
                <br />
            </p>
        </blockquote>

        <blockquote>
            <p>
                <a target="_blank" href="https://eccv2018.org/openaccess/content_ECCV_2018/papers/Zeming_Li_DetNet_Design_Backbone_ECCV_2018_paper.pdf"> DetNet: A Backbone network for Object Detection</a>
                <br />
                <b>Zeming Li, </b> Chao Peng, Gang Yu, Xiangyu Zhang, Yangdong Deng, Jian Sun
                <br />
                <i>ECCV, 2018</i>
                <br />
            </p>
        </blockquote>

        <blockquote>
            <p>
                <a target="_blank" href="https://openaccess.thecvf.com/content_cvpr_2018/CameraReady/0836.pdf" class=""> MegDet: A Large Mini-Batch ObjectDetector</a>
                <br />
                Chao Peng<sup>+</sup> , Tete Xiao<sup>+</sup> , <b>Zeming Li<sup>+</sup> </b>, Yuning Jiang, Xiangyu Zhang, Kai Jia, Gang Yu, Jian Sun
                <br />
                <i>CVPR <b>spotlight</b>, 2018</i>
            </p>
        </blockquote>

        <blockquote>
            <p>
                <a target="_blank" href="#">R-FCN++: Towards Accurate Region-based Fully Convolutional Networks for Object Detection</a>
                <br />
                <b>Zeming Li</b>, Yilun Chen, Gang Yu, Yangdong Deng
                <br />
                <i>AAAI <b>Oral</b>, 2018</i>
            </p>
        </blockquote>

        <!--        Reports             -->

        <a name="Reports"><h2>Reports</h2></a>
        <blockquote>
            <p>
                <a target="_blank" href="https://arxiv.org/pdf/2012.00720"> Fully Convolutional Networks for Panoptic Segmentation </a>
                <br />
                Yanwei Li, Hengshuang Zhao, Xiaojuan Qi, Liwei Wang, <b>Zeming Li</b>, Jian Sun, Jiaya Jia
                <br />
                <i>Report, 2020,</i>
                <font color="#808080">
                    <b>
                        <a href="https://github.com/yanwei-li/PanopticFCN">
                            <font color="#FF0000">code/models</font>
                        </a>
                    </b>
                </font>
            </p>
        </blockquote>

        <blockquote>
            <p>
                <a target="_blank" href="https://arxiv.org/pdf/2012.03544"> End-to-End Object Detection with Fully Convolutional Network </a>
                <br />
                Jianfeng Wang, Lin Song, <b>Zeming Li</b>, Hongbin Sun, Jian Sun, Nanning Zheng
                <br />
                <i>Report, 2020,</i>
                <font color="#808080">
                    <b>
                        <a href="https://github.com/Megvii-BaseDetection/DeFCN">
                            <font color="#FF0000">code/models</font>
                        </a>
                    </b>
                </font>
            </p>
        </blockquote>


        <blockquote>
            <p>
                <a target="_blank" href="https://arxiv.org/pdf/2011.13677.pdf"> Self-EMD: Self-Supervised Object Detection without ImageNet </a>
                <br />
                Songtao Liu, <b>Zeming Li</b>, Jian Sun
                <br />
                <i>Report, 2020</i>
            </p>
        </blockquote>

        <blockquote>
            <p>
                <a target="_blank" href="https://arxiv.org/pdf/2010.01929"> EqCo: Equivalent Rules for Self-supervised Contrastive Learning</a>
                <br />
                Benjin Zhu, Junqiang Huang, <b>Zeming Li</b>, Xiangyu Zhang, Jian Sun
                <br />
                <i>Report, 2020</i>
                <font color="#808080">
                    <b>
                        <a href="https://github.com/poodarchu/SelfSup">
                            <font color="#FF0000">code/models</font>
                        </a>
                    </b>
                </font>
            </p>
        </blockquote>

        <blockquote>
            <p>
                <a target="_blank" href="https://arxiv.org/pdf/2007.03496.pdf"> AutoAssign: Differentiable Label Assignment for Dense Object Detection</a>
                <br />
                Benjin Zhu, Jianfeng Wang, Zhengkai Jiang, Fuhang Zong, Songtao Liu, <b>Zeming Li</b>, Jian Sun
                <br />
                <i>Report, 2020</i>
                <font color="#808080">
                    <b>
                        <a href="https://github.com/Megvii-BaseDetection/AutoAssign">
                            <font color="#FF0000">code/models</font>
                        </a>
                    </b>
                </font>
            </p>
        </blockquote>

        <blockquote>
            <p>
                <a target="_blank" href="https://arxiv.org/abs/2004.12432"> Stitcher: Feedback-driven Data Provider for Object Detection</a>
                <br />
                Yukang Chen, Peizhen Zhang, <b>Zeming Li</b>, Yanwei Li, Xiangyu Zhang, Gaofeng Meng, Shiming Xiang, Jian Sun, Jiaya Jia
                <br />
                <i>Report, 2020</i>
            </p>
        </blockquote>

        <blockquote>
            <p>
                <a target="_blank" href="https://arxiv.org/abs/1908.09492"> Class-balanced Grouping and Sampling for Point Cloud 3D Object Detection</a>
                <br />
                Benjin Zhu, Zhengkai Jiang, Xiangxin Zhou, <b>Zeming Li</b>, Gang Yu
                <br />
                <i>Report, 2019,</i>
                <font color="#808080">
                    <b>
                        <a href="https://github.com/poodarchu/Det3D">
                            <font color="#FF0000">code/models</font>
                        </a>
                    </b>
                </font>
            </p>
        </blockquote>

        <blockquote>
            <p>
                <a target="_blank" href="https://arxiv.org/pdf/1711.07264.pdf"> Light-Head R-CNN: In Defense of Two-Stage Object Detector</a>
                <br />
                <b>Zeming Li, </b> Chao Peng, Gang Yu, Xiangyu Zhang, Yangdong Deng, Jian Sun
                <br />
                <i>Report, 2017,</i>
                <font color="#808080">
                    <b>
                        <a href="https://github.com/zengarden/light_head_rcnn">
                            <font color="#FF0000">code/models</font>
                        </a>
                    </b>
                </font>
            </p>
        </blockquote>

        <!-- Awards -->
        <a name="Awards"><h2>Awards</h2></a>
        I won the famous object detection challenge <a href="https://cocodataset.org/#home">COCO</a> as the leading player during 2017,2018,2019.
        <font size="3">
            <ul>
                <li><a href="http://cocodataset.org/workshop/coco-mapillary-iccv-2019.html" target="_blank">COCO and Mapillary Challenges 2019 Competition</a> Winner Award, and Best Paper Award, ICCV 2019</li>

                <li><a href="https://www.nuscenes.org/object-detection?externalData=all&mapData=all&modalities=Any" target="_blank"> WAD nuScenes 3D Detection Competition</a>, Winnder Award, CVPR 2019</li>

                <li>
                    <a href="https://cocodataset.org/workshop/coco-mapillary-eccv-2018.html" target="_blank">COCO and Mapillary Challenges 2018 Competition</a> Winner Award, ECCV 2018.
                    <a href="https://mp.weixin.qq.com/s/K36j2JcTWPV1velUqyy6pA" target="_blank">ChinaMedia</a>
                </li>

                <li>
                    We have won the first place in
                    <a target="_blank" href="https://www.kaggle.com/c/cvpr-2018-autonomous-driving/leaderboard"> Video Instance Segmentation </a> in the
                    <a target="_blank" href="http://www.wad.ai/index.html"> WAD2018 (Workshop on Autonomous Driving) Challenge. </a>
                </li>

                <li>
                    We have won <a target="_blank" href="https://places-coco2017.github.io/"> COCO and Places Challenges 2017 </a> with two champions on:
                    <a target="_blank" href="http://cocodataset.org/#detections-leaderboard"> COCO Detection </a> and <a target="_blank" href="http://cocodataset.org/#keypoints-leaderboard"> COCO Keypoint </a>.
                </li>

                <li>I'm first place in <a href="http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&compid=4">Pascal VOC Detection Leaderboard </a> from 20-Nov-2016 to 01-Mar-2018.</li>
            </ul>
        </font>

        <!-- Services -->
        <div>
            <h1>Services</h1>
            <b> Recent Conference Review</b>: NeurIPS2020, AAAI2021, ICLR2021, CVPR2021, ICML2021
        </div>
        <!-- Links -->
        <div>
            <h1>Links</h1>
            <p>
                Research Collaborator:
                <a target="_blank" href="http://www.jiansun.org/">孙剑(Jian Sun)</a>, <a target="_blank" href="http://www.skicyyu.org/">俞刚(Gang Yu)</a>,
                <a target="_blank" href="http://www.pengchao.org/">彭超(Peng Chao)</a>
            </p>
        </div>

        visit
        <a href="https://www.easycounter.com/">
            <img src="https://www.easycounter.com/counter.php?zengarden" border="0" alt="stats counter" />
        </a>

        <font size="2" ; color="#A0A0A0" ;>
            <p style="text-align: center;">Updating time: 2020.10.28</p>
        </font>
        <!--
All Rights Reserved by Zeming Li. Part of page is generated by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
-->
        <script
                type="text/javascript"
                src="//rf.revolvermaps.com/0/0/6.js?i=5x3ebj080sx&amp;m=7&amp;c=e63100&amp;cr1=ffffff&amp;f=arial&amp;l=0&amp;bv=90&amp;lx=-420&amp;ly=420&amp;hi=20&amp;he=7&amp;hc=a8ddff&amp;rs=80"
                async="async"
        ></script>
    </div>
</div>
</body>
</html>
